\chapter{Introduction}
Many computer vision problems can be considered as an image-to-image translation problem, mapping an image from one domain to another. For example, colorization \cite{DBLP:journals/corr/LarssonMS16} \cite{DBLP:journals/corr/ZhangIE16} (grayscale $\rightarrow$ color), super resolution \cite{DBLP:journals/corr/LedigTHCATTWS16} \cite{DBLP:journals/corr/LaiHA017} (low resolution $\rightarrow$ high resolution), and style transfer \cite{DBLP:journals/corr/GatysEB15a} \cite{DBLP:journals/corr/LiW16} \cite{DBLP:journals/corr/LiaoYYHK17} (image $\rightarrow$ style image). \\
Gatys et al.\cite{DBLP:journals/corr/GatysEB15a} proposed artistic style transfer in his work. By using convolutional neural networks, the author translated any input image into the style of a painting image. Later many works were done in image-to-image translation tasks e.g.\cite{DBLP:journals/corr/LiW16} \cite{DBLP:journals/corr/LiaoYYHK17} where most of them used convolutional neural networks to do the synthesis.\\
Later, Generative Adversarial Network(GAN)\cite{goodfellow2014generative} was proposed which provided astounding results in many tasks, e.g, image generation \cite{DBLP:journals/corr/RadfordMC15} \cite{DBLP:journals/corr/DentonCSF15}, image editing\cite{DBLP:journals/corr/ZhuKSE16}, text2image\cite{DBLP:journals/corr/ZhangXLZHWM16}, image inpainting\cite{DBLP:journals/corr/PathakKDDE16}, image-to-image translation tasks\cite{cyclegan} \cite{pix2pix} etc. Isola et al.\cite{pix2pix} proposed a GAN based approach to transfer input of one domain,$x$ to another domain,$y$ by training on paired image dataset. But accumulating such paired images of both domains is hard and ineffective. We might not get paired images to train for many specific tasks of image-to-image translation. Recently, for training unpaired images, where there is no correspondence between domain $x$ and domain $y$ images, many authors published incredible works such as, CycleGAN\cite{cyclegan}, DualGAN\cite{DBLP:journals/corr/YiZTG17}, DiscoGAN \cite{DBLP:journals/corr/KimCKLK17}, UNIT\cite{DBLP:journals/corr/LiuBK17} etc.\\ 
In unsupervised setting, adversarial loss alone can't solve the infinite mapping problem in the target domain. Zhu et al.\cite{cyclegan} proposed that, by using cycle consistency loss, the network would be able generate images where the possible infinite mappings of target domain would be reduced.\\
Similar work was proposed in UNIT\cite{DBLP:journals/corr/LiuBK17}, where the space-latent assumption implied that the two corresponding sets of different domains can be mapped to a same latent representation in a shared-latent space. To exploit this assumption, the authors proposed a framework based on generative adversarial network(GAN) and variational autoencoders(VAEs).\\
The authors in CartoonGAN\cite{cartoonGAN} paper made an approach in cartoon stylization, transferring a set of real world images to cartoon domain. For this approach, no pairing was required during the training. In this paper, we work on - \textit{Cartoon-to-Real} image translation task. During the training procedure, no pairing of images was required. We extracted cartoon images from different cartoon movies and real images from internet, i.e. flickr. Using our Cartoon-to-Real, we achieve significant result in translating the cartoon images to realistic ones.   

\section{Problem domain}
In recent times, there have been many works on remaking cartoon movies into real live action films e.g. \textit{The Lion King(2019)}, \textit{Beauty and the Beast(2017)} etc. Translating the cartoon images into real world images is a tedious and tiresome work for the film industry. Meanwhile, existing image editing software/algorithms is more costly for bringing CGI effects into films. Therefore, techniques that can automatically transform cartoon images into real world images are very helpful and tremendous amount of time can be saved. Tools such as this also provide as an additional component in photoshop and image editing works. \\
In our work, we do this translation of cartoon images into real world images. For doing this task, we did not need any pairing between two sets of images, cartoon and real world images. We exploited the ideas of cycle consistency\cite{cyclegan} and shared-latent space assumption\cite{DBLP:journals/corr/LiuBK17} and provided effective results in cartoon-to-real images translation.  

\section{Motivation}
CartoonGAN\cite{cartoonGAN} paper proposed a GAN based approach on transforming real world images in cartoon domain. We became interested to transfer the opposite of CartoonGAN, that is, transforming cartoon images to real world images. We see that, many recent movies of cartoons is being made live action film so we were interested in such domain.
\subsection{Why GAN}
Generative adversarial networks provide state of the art results in image-to-image translation tasks. Recently CycleGAN\cite{cyclegan}, UNIT\cite{DBLP:journals/corr/LiuBK17}, SingleGAN\cite{SingleGAN} provides astounding results in this domain. CycleGAN exploits the concept of \textit{cycle consistency loss} where the infinite mappings between two domains is reduced. Similar to \textit{cycle consistency loss} UNIT\cite{DBLP:journals/corr/LiuBK17} proposed another assumption known as shared latent space, where both domains have same shared latent representation. These GAN based approaches provides more effective and efficient results than any other approaches.
 
\section{Contribution}
We implemented cartoon to real world images using Generative Adversarial Network on our unpaired image dataset. For the cartoon domain, we've collected almost 3.1K images scrapped from various movies, e.g. \textit{Pokemon}, \textit{My Neigbour Totoro} and \textit{Kiki’s Delivery}. We used flickr dataset for the real images’ domain. Images are resized to 128×128 resolution. These images,real and cartoon domain images, have no correlations between them We achieved significant results in translating the cartoon images to realistic ones. 